{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe20faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from requests import get\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4433fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch : 16.1.1 - TÃ©lÃ©chargement via API Officielle...\n",
      "Analyse de 694 objets...\n",
      " SuccÃ¨s ! 250 objets rÃ©cupÃ©rÃ©s.\n",
      "shape: (10, 5)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Name              â”† Price â”† AD  â”† AbilityHaste â”† Lethality â”‚\n",
      "â”‚ ---               â”† ---   â”† --- â”† ---          â”† ---       â”‚\n",
      "â”‚ str               â”† i64   â”† i64 â”† f64          â”† f64       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ Boots             â”† 300   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Faerie Charm      â”† 200   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Rejuvenation Bead â”† 300   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Giant's Belt      â”† 900   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Cloak of Agility  â”† 600   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Blasting Wand     â”† 850   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Sapphire Crystal  â”† 300   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Ruby Crystal      â”† 400   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Cloth Armor       â”† 300   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â”‚ Chain Vest        â”† 800   â”† 0   â”† 0.0          â”† 0.0       â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "#1 Avoir la derniÃ¨re version\n",
    "\n",
    "def get_latest_version():\n",
    "    try:\n",
    "        return requests.get(\"https://ddragon.leagueoflegends.com/api/versions.json\").json()[0]\n",
    "    except:\n",
    "        return \"16.1.1\"\n",
    "\n",
    "def clean_html(raw_html):\n",
    "    if not raw_html: return \"\"\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    return re.sub(cleanr, ' ', raw_html).replace('\\n', ' ').strip().lower()\n",
    "\n",
    "def extract_stat_from_text(regex, text):\n",
    "    match = re.search(regex, text)\n",
    "    return float(match.group(1)) if match else 0.0\n",
    "\n",
    "#2 RÃ©cupÃ©ration des donnÃ©es complÃ¨tes des objets via l'API officielle\n",
    "def get_items_complete():\n",
    "    version = get_latest_version()\n",
    "    print(f\"Patch : {version} - TÃ©lÃ©chargement via API Officielle...\")\n",
    "\n",
    "    url = f\"https://ddragon.leagueoflegends.com/cdn/{version}/data/en_US/item.json\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Erreur API Riot\")\n",
    "        return None\n",
    "\n",
    "    data = response.json()['data']\n",
    "    items_list = []\n",
    "\n",
    "    print(f\"Analyse de {len(data)} objets...\")\n",
    "\n",
    "    for item_id, details in data.items():\n",
    "        # les bons objets seulement\n",
    "        if details.get('maps', {}).get('11') is not True:\n",
    "            continue\n",
    "\n",
    "        gold = details.get('gold', {})\n",
    "        if not gold.get('purchasable', False):\n",
    "            continue\n",
    "\n",
    "        if 'requiredChampion' in details:\n",
    "            continue\n",
    "            \n",
    "        is_trinket = \"Trinket\" in details.get('tags', [])\n",
    "        if gold['total'] == 0 and not is_trinket:\n",
    "            continue\n",
    "\n",
    "        #les Ã©lÃ©ments qeu je veux seulement\n",
    "        stats = details.get('stats', {})\n",
    "        \n",
    "     \n",
    "        tags = details.get('tags', []) \n",
    "        \n",
    "        raw_desc = details.get('description', '')\n",
    "        clean_desc = clean_html(raw_desc)\n",
    "        \n",
    "        row = {\n",
    "            \"ID\": item_id,\n",
    "            \"Name\": details['name'],\n",
    "            \"Price\": gold['total'],\n",
    "            \"Sell_Price\": gold['sell'],\n",
    "            \n",
    "            \n",
    "            \"AD\": stats.get('FlatPhysicalDamageMod', 0),\n",
    "            \"AP\": stats.get('FlatMagicDamageMod', 0),\n",
    "            \"HP\": stats.get('FlatHPPoolMod', 0),\n",
    "            \"Armor\": stats.get('FlatArmorMod', 0),\n",
    "            \"MR\": stats.get('FlatSpellBlockMod', 0),\n",
    "            \"Mana\": stats.get('FlatMPPoolMod', 0),\n",
    "            \"AttackSpeed\": stats.get('PercentAttackSpeedMod', 0),\n",
    "            \"MoveSpeed\": stats.get('FlatMovementSpeedMod', 0),\n",
    "            \"CritChance\": stats.get('FlatCritChanceMod', 0),\n",
    "            \n",
    "            \n",
    "            \"tag1\": tags[0] if len(tags) > 0 else \"None\",\n",
    "            \"tag2\": tags[1] if len(tags) > 1 else \"None\",\n",
    "            \"tag3\": tags[2] if len(tags) > 2 else \"None\",\n",
    "            \n",
    "            #Extraction Regex ( les LARMES)\n",
    "            \"AbilityHaste\": extract_stat_from_text(r'(\\d+)\\s*ability haste', clean_desc),\n",
    "            \"Lethality\": extract_stat_from_text(r'(\\d+)\\s*lethality', clean_desc),\n",
    "            \"MagicPen\": extract_stat_from_text(r'(\\d+)\\s*magic penetration', clean_desc),\n",
    "            \"Omnivamp\": extract_stat_from_text(r'(\\d+)%\\s*omnivamp', clean_desc),\n",
    "            \"LifeSteal\": extract_stat_from_text(r'(\\d+)%\\s*life steal', clean_desc),\n",
    "            \n",
    "            \"ImageURL\": f\"https://ddragon.leagueoflegends.com/cdn/{version}/img/item/{details['image']['full']}\"\n",
    "        }\n",
    "\n",
    "        items_list.append(row)\n",
    "\n",
    "    df = pl.DataFrame(items_list)\n",
    "    return df\n",
    "\n",
    "#3 tourne stp\n",
    "if __name__ == \"__main__\":\n",
    "    df_objets = get_items_complete()\n",
    "    \n",
    "    if df_objets is not None and not df_objets.is_empty():\n",
    "        print(f\" SuccÃ¨s ! {len(df_objets)} objets rÃ©cupÃ©rÃ©s.\")\n",
    "        print(df_objets.select([\"Name\", \"Price\", \"AD\", \"AbilityHaste\", \"Lethality\"]).head(10))\n",
    "        \n",
    "        # Sauvegarde\n",
    "        # df_objets.write_csv(\"objets_complets_regression.csv\", separator=\";\")\n",
    "    else:\n",
    "        print(\"Toujours vide... bizarre l'ambiance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78bde38",
   "metadata": {},
   "source": [
    "sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2442188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_objets.write_csv(\"prÃ©sentation_objets_complets.csv\", separator=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31e4ac",
   "metadata": {},
   "source": [
    "modÃ¨les ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54fee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes utilisÃ©es pour la prÃ©diction (X) :\n",
      "['AD', 'AP', 'HP', 'Armor', 'MR', 'Mana', 'AttackSpeed', 'MoveSpeed', 'CritChance', 'AbilityHaste', 'Lethality', 'MagicPen', 'Omnivamp', 'LifeSteal']\n"
     ]
    }
   ],
   "source": [
    "#1 On chope un df avec les colones utiles\n",
    "colonnes_a_exclure = [\"Name\", \"Price\", \"Sell_Price\", \"ImageURL\", \"ID\",\"Sell_Price\",\"tag1\",\"tag2\",\"tag3\"]\n",
    "X = df_objets.drop([c for c in colonnes_a_exclure if c in df_objets.columns])\n",
    "\n",
    "y = df_objets.select(\"Price\")\n",
    "\n",
    "#2 VÃ©rification\n",
    "print(\"Colonnes utilisÃ©es pour la prÃ©diction (X) :\")\n",
    "print(X.columns)\n",
    "\n",
    "#3 SÃ©paration train/test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11071fbf",
   "metadata": {},
   "source": [
    "Recherche brute du meilleur modÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntraÃ®nement en cours...\n",
      "\n",
      "--- erreur moyenne en gold ---\n",
      "shape: (12, 2)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Modele          â”† Erreur_Moyenne â”‚\n",
      "â”‚ ---             â”† ---            â”‚\n",
      "â”‚ str             â”† f64            â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ RandomForest    â”† 301.41527      â”‚\n",
      "â”‚ DecisionTree    â”† 310.615532     â”‚\n",
      "â”‚ GradientBoost   â”† 344.217077     â”‚\n",
      "â”‚ Ridge           â”† 346.397198     â”‚\n",
      "â”‚ Linear          â”† 346.497967     â”‚\n",
      "â”‚ â€¦               â”† â€¦              â”‚\n",
      "â”‚ KNN             â”† 418.131977     â”‚\n",
      "â”‚ ElasticNet      â”† 511.023323     â”‚\n",
      "â”‚ SVR             â”† 887.892069     â”‚\n",
      "â”‚ Dummy (Base)    â”† 958.3378       â”‚\n",
      "â”‚ GaussianProcess â”† 1804.267712    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Liste des modÃ¨les \n",
    "modeles = [\n",
    "    (\"Dummy (Base)\", DummyRegressor()), #Le modÃ¨le de base\n",
    "    (\"Linear\", LinearRegression()),\n",
    "    (\"Lasso\", Lasso(alpha=1.0)),\n",
    "    (\"Ridge\", Ridge(alpha=1.0)),\n",
    "    (\"ElasticNet\", ElasticNet(alpha=1.0, l1_ratio=0.5)),\n",
    "    (\"SVR\", SVR(C=1.0, epsilon=0.1)),\n",
    "    (\"KNN\", KNeighborsRegressor(n_neighbors=5)),\n",
    "    (\"GaussianProcess\", GaussianProcessRegressor()),\n",
    "    (\"DecisionTree\", DecisionTreeRegressor()),\n",
    "    (\"RandomForest\", RandomForestRegressor()),\n",
    "    (\"GradientBoost\", GradientBoostingRegressor()),\n",
    "    (\"NeuralNet\", MLPRegressor(hidden_layer_sizes=(30,), max_iter=10000))\n",
    "]\n",
    "\n",
    "resultats = {}\n",
    "\n",
    "print(\"EntraÃ®nement en cours...\")\n",
    "\n",
    "for nom, modele in modeles:\n",
    "    pipe = make_pipeline(StandardScaler(), modele)\n",
    "    \n",
    "   \n",
    "    scores = cross_val_score(pipe, X_tr, y_tr, cv=5, scoring='neg_mean_absolute_error')\n",
    "    resultats[nom] = -scores \n",
    "\n",
    "# CrÃ©ation du DataFrame Polars\n",
    "df_res = pl.DataFrame(resultats)\n",
    "\n",
    "# Affichage des moyennes (classÃ©es par la plus petite erreur)\n",
    "print(\"\\n--- erreur moyenne en gold ---\")\n",
    "moyennes = df_res.mean().transpose(include_header=True, header_name=\"Modele\", column_names=[\"Erreur_Moyenne\"])\n",
    "print(moyennes.sort(\"Erreur_Moyenne\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5905ea0",
   "metadata": {},
   "source": [
    "Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimisation de la ForÃªt en cours...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      " MEILLEURE COMBINAISON TROUVÃ‰E :\n",
      "HyperparamÃ¨tres : {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Erreur Moyenne OptimisÃ©e : 298.56 Gold\n"
     ]
    }
   ],
   "source": [
    "#1. On dÃ©finit le modÃ¨le \n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "#2. On dÃ©finit la \"Grille\" des hyperparamÃ¨tres\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  \n",
    "    'max_depth': [None, 10, 20],      \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4]     \n",
    "}\n",
    "\n",
    "#3. On lance la recherche (GridSearch)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Optimisation de la ForÃªt en cours...\")\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "#4. RÃ©sultats\n",
    "best_score = -grid_search.best_score_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"\\n MEILLEURE COMBINAISON TROUVÃ‰E :\")\n",
    "print(f\"HyperparamÃ¨tres : {best_params}\")\n",
    "print(f\"Erreur Moyenne OptimisÃ©e : {best_score:.2f} Gold\")\n",
    "\n",
    "#5. RÃ©cupÃ©rer le modÃ¨le optimisÃ©\n",
    "mon_super_modele = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e5ed1",
   "metadata": {},
   "source": [
    "Validation ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d3e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RÃ‰SULTATS FINAUX SUR LE TEST SET ---\n",
      " Erreur Moyenne (MAE) : 387.47 Gold\n",
      " PrÃ©cision (RÂ²)       : 0.66 (1.0 = Parfait, 0.0 = Nul)\n",
      "\n",
      "--- TOP 5 DES PLUS GROSSES ERREURS ---\n",
      "shape: (5, 4)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Prix_Reel â”† Prix_Predit â”† Ecart        â”† Abs_Ecart   â”‚\n",
      "â”‚ ---       â”† ---         â”† ---          â”† ---         â”‚\n",
      "â”‚ i64       â”† f64         â”† f64          â”† f64         â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 2500      â”† 346.332866  â”† -2153.667134 â”† 2153.667134 â”‚\n",
      "â”‚ 950       â”† 2996.91373  â”† 2046.91373   â”† 2046.91373  â”‚\n",
      "â”‚ 900       â”† 2877.040476 â”† 1977.040476  â”† 1977.040476 â”‚\n",
      "â”‚ 1300      â”† 3029.976444 â”† 1729.976444  â”† 1729.976444 â”‚\n",
      "â”‚ 1150      â”† 2180.812698 â”† 1030.812698  â”† 1030.812698 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "#1. Faire les prÃ©dictions\n",
    "predictions = mon_super_modele.predict(X_te)\n",
    "\n",
    "#2. Calculer les scores\n",
    "mae = mean_absolute_error(y_te, predictions)\n",
    "r2 = r2_score(y_te, predictions)\n",
    "\n",
    "print(f\"--- RÃ‰SULTATS FINAUX SUR LE TEST SET ---\")\n",
    "print(f\" Erreur Moyenne (MAE) : {mae:.2f} Gold\")\n",
    "print(f\" PrÃ©cision (RÂ²)       : {r2:.2f} \")\n",
    "\n",
    "#3. CrÃ©er un tableau comparatif\n",
    "df_verif = pl.DataFrame({\n",
    "    \"Prix_Reel\": y_te.to_numpy().flatten(),\n",
    "    \"Prix_Predit\": predictions.flatten()\n",
    "})\n",
    "\n",
    "\n",
    "df_verif = df_verif.with_columns(\n",
    "    (pl.col(\"Prix_Predit\") - pl.col(\"Prix_Reel\")).alias(\"Ecart\")\n",
    ")\n",
    "\n",
    "#4. Afficher les plus grosses erreurs\n",
    "print(\"\\n--- TOP 5 DES PLUS GROSSES ERREURS ---\")\n",
    "# On ajoute .round(2) pour que ce soit plus grrr\n",
    "print(df_verif.with_columns(pl.col(\"Ecart\").abs().alias(\"Abs_Ecart\"))\n",
    "              .sort(\"Abs_Ecart\", descending=True)\n",
    "              .head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba956f",
   "metadata": {},
   "source": [
    "Nouvelle recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0c081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec820ed6272457dba652a282ae81476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65\n",
      "[LightGBM] [Info] Number of data points in the train set: 187, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 1999.839572\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "                               Adjusted R-Squared  R-Squared    RMSE  \\\n",
      "Model                                                                  \n",
      "HuberRegressor                               0.70       0.77  514.82   \n",
      "PassiveAggressiveRegressor                   0.70       0.77  517.99   \n",
      "BayesianRidge                                0.69       0.76  527.21   \n",
      "RidgeCV                                      0.69       0.76  528.29   \n",
      "Ridge                                        0.69       0.76  528.29   \n",
      "LassoCV                                      0.68       0.76  529.00   \n",
      "Lasso                                        0.68       0.76  529.40   \n",
      "LassoLars                                    0.68       0.76  529.41   \n",
      "SGDRegressor                                 0.68       0.76  529.48   \n",
      "LinearRegression                             0.68       0.76  529.78   \n",
      "TransformedTargetRegressor                   0.68       0.76  529.78   \n",
      "Lars                                         0.68       0.76  529.78   \n",
      "LarsCV                                       0.68       0.76  529.78   \n",
      "LassoLarsIC                                  0.68       0.76  529.78   \n",
      "LassoLarsCV                                  0.68       0.76  529.78   \n",
      "RANSACRegressor                              0.68       0.75  532.93   \n",
      "KNeighborsRegressor                          0.63       0.71  575.00   \n",
      "GradientBoostingRegressor                    0.62       0.71  579.39   \n",
      "PoissonRegressor                             0.59       0.68  601.43   \n",
      "ExtraTreesRegressor                          0.56       0.66  621.82   \n",
      "ElasticNetCV                                 0.55       0.65  629.96   \n",
      "RandomForestRegressor                        0.53       0.64  643.88   \n",
      "BaggingRegressor                             0.53       0.64  646.87   \n",
      "ElasticNet                                   0.52       0.63  650.06   \n",
      "LGBMRegressor                                0.51       0.62  660.74   \n",
      "HistGradientBoostingRegressor                0.50       0.61  666.42   \n",
      "OrthogonalMatchingPursuitCV                  0.47       0.59  687.95   \n",
      "XGBRegressor                                 0.46       0.58  694.04   \n",
      "DecisionTreeRegressor                        0.44       0.57  705.81   \n",
      "AdaBoostRegressor                            0.38       0.52  742.32   \n",
      "TweedieRegressor                             0.35       0.50  758.78   \n",
      "ExtraTreeRegressor                           0.28       0.44  802.01   \n",
      "OrthogonalMatchingPursuit                   -0.09       0.15  985.90   \n",
      "NuSVR                                       -0.32      -0.02 1081.25   \n",
      "DummyRegressor                              -0.38      -0.07 1105.70   \n",
      "SVR                                         -0.91      -0.48 1301.65   \n",
      "QuantileRegressor                           -0.97      -0.52 1321.69   \n",
      "LinearSVR                                   -2.97      -2.08 1878.70   \n",
      "KernelRidge                                 -3.33      -2.36 1962.27   \n",
      "MLPRegressor                                -3.58      -2.54 2016.45   \n",
      "GaussianProcessRegressor                   -49.71     -38.26 6711.56   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "HuberRegressor                       0.87  \n",
      "PassiveAggressiveRegressor           0.18  \n",
      "BayesianRidge                        0.23  \n",
      "RidgeCV                              0.13  \n",
      "Ridge                                0.02  \n",
      "LassoCV                              0.13  \n",
      "Lasso                                0.02  \n",
      "LassoLars                            0.02  \n",
      "SGDRegressor                         0.07  \n",
      "LinearRegression                     0.02  \n",
      "TransformedTargetRegressor           0.10  \n",
      "Lars                                 0.19  \n",
      "LarsCV                               0.40  \n",
      "LassoLarsIC                          0.02  \n",
      "LassoLarsCV                          0.07  \n",
      "RANSACRegressor                      0.28  \n",
      "KNeighborsRegressor                  0.03  \n",
      "GradientBoostingRegressor            0.15  \n",
      "PoissonRegressor                     0.13  \n",
      "ExtraTreesRegressor                  0.17  \n",
      "ElasticNetCV                         0.31  \n",
      "RandomForestRegressor                0.25  \n",
      "BaggingRegressor                     0.30  \n",
      "ElasticNet                           0.08  \n",
      "LGBMRegressor                        1.21  \n",
      "HistGradientBoostingRegressor        1.18  \n",
      "OrthogonalMatchingPursuitCV          0.07  \n",
      "XGBRegressor                         2.43  \n",
      "DecisionTreeRegressor                0.03  \n",
      "AdaBoostRegressor                    1.23  \n",
      "TweedieRegressor                     0.09  \n",
      "ExtraTreeRegressor                   0.09  \n",
      "OrthogonalMatchingPursuit            0.04  \n",
      "NuSVR                                0.11  \n",
      "DummyRegressor                       0.02  \n",
      "SVR                                  0.02  \n",
      "QuantileRegressor                    1.15  \n",
      "LinearSVR                            0.14  \n",
      "KernelRidge                          0.24  \n",
      "MLPRegressor                         0.23  \n",
      "GaussianProcessRegressor             0.08  \n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "\n",
    "models, predictions = reg.fit(\n",
    "    X_tr.to_pandas(), \n",
    "    X_te.to_pandas(), \n",
    "    y_tr.to_pandas(), \n",
    "    y_te.to_pandas()\n",
    ")\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027ce52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‹ï¸ EntraÃ®nement du HuberRegressor...\n",
      "\n",
      "--- ğŸ“Š RÃ‰SULTATS HUBER REGRESSOR ---\n",
      "RÂ² Train (Apprentissage) : 0.839\n",
      "RÂ² Test (GÃ©nÃ©ralisation) : 0.769\n",
      "Erreur Moyenne (MAE)     : 359.9 Gold\n",
      "\n",
      "--- âš–ï¸ COMPARAISON VS RANDOM FOREST ---\n",
      "Huber RÂ² Test : 0.769\n",
      "Forest RÂ² Test: (Votre Score PrÃ©cÃ©dent, probablement ~0.55 - 0.60)\n",
      "âœ… LE HUBER GAGNE : L'Ã©conomie de LoL est bien linÃ©aire !\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "#1 CrÃ©ation du Pipeline\n",
    "\n",
    "pipe_huber = make_pipeline(StandardScaler(), HuberRegressor(epsilon=1.35, max_iter=2000))\n",
    "\n",
    "#2. EntraÃ®nement\n",
    "print(\"EntraÃ®nement du HuberRegressor...\")\n",
    "# On utilise .values.ravel() pour transformer y en un simple tableau 1D (Ã©vite les warnings)\n",
    "pipe_huber.fit(X_tr.to_pandas(), y_tr.to_pandas().values.ravel())\n",
    "\n",
    "#3. PrÃ©dictions\n",
    "y_pred_train = pipe_huber.predict(X_tr.to_pandas())\n",
    "y_pred_test = pipe_huber.predict(X_te.to_pandas())\n",
    "\n",
    "#4. Calcul des scores\n",
    "r2_train = r2_score(y_tr.to_pandas(), y_pred_train)\n",
    "r2_test = r2_score(y_te.to_pandas(), y_pred_test)\n",
    "mae_test = mean_absolute_error(y_te.to_pandas(), y_pred_test)\n",
    "\n",
    "print(\"\\n--- RÃ‰SULTATS HUBER REGRESSOR ---\")\n",
    "print(f\"RÂ² Train (Apprentissage) : {r2_train:.3f}\")\n",
    "print(f\"RÂ² Test (GÃ©nÃ©ralisation) : {r2_test:.3f}\")\n",
    "print(f\"Erreur Moyenne (MAE)     : {mae_test:.1f} Gold\")\n",
    "\n",
    "#5. Extraction de la Gold Value\n",
    "huber_model = pipe_huber.steps[1][1] \n",
    "\n",
    "\n",
    "#terminado\n",
    "print(f\"Huber RÂ² Test : {r2_test:.3f}\")\n",
    "\n",
    "\n",
    "if r2_test > 0.60:\n",
    "    print(\"L'Ã©conomie de LoL semble vachement bien linÃ©aire !\")\n",
    "else:\n",
    "    print(\"Eh vasy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf5979e",
   "metadata": {},
   "source": [
    "Enregistrement du modÃ¨le final + utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ EntraÃ®nement final en cours...\n",
      "âœ… ModÃ¨le entraÃ®nÃ© !\n",
      "ğŸ‰ SuccÃ¨s ! Le fichier 'lol_price_model.pkl' est prÃªt.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#1 : On prend la liste des colonnes\n",
    "cols_features = [\n",
    "    \"AD\", \"AP\", \"HP\", \"Armor\", \"MR\", \"Mana\", \n",
    "    \"AttackSpeed\", \"MoveSpeed\", \"CritChance\", \n",
    "    \"AbilityHaste\", \"Lethality\", \"MagicPen\", \"Omnivamp\", \"LifeSteal\"\n",
    "]\n",
    "\n",
    "#2 : On prÃ©pare les donnÃ©es d'entraÃ®nement (converssion aussi en vrai)\n",
    "X = df_objets.select(cols_features).to_pandas()\n",
    "y = df_objets.select(\"Price\").to_pandas().values.ravel() # .ravel() aplatit le tableau\n",
    "\n",
    "#3 : On crÃ©e et entraÃ®ne le Pipeline Final \n",
    "modele_final = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    HuberRegressor(epsilon=1.35, max_iter=2000)\n",
    ")\n",
    "\n",
    "print(\"EntraÃ®nement final en cours...\")\n",
    "modele_final.fit(X, y)\n",
    "print(\"ModÃ¨le entraÃ®nÃ© !\")\n",
    "\n",
    "#4 : On sauvegarde les paramÃ¨tres\n",
    "package = {\n",
    "    \"pipeline\": modele_final, \n",
    "    \"features\": cols_features, \n",
    "    \"description\": \"ModÃ¨le HuberRegressor pour prÃ©diction prix LoL\"\n",
    "}\n",
    "\n",
    "#5 : Enregistrement sur le disque dur ( god bless)\n",
    "filename = \"lol_price_model.pkl\"\n",
    "joblib.dump(package, filename)\n",
    "\n",
    "print(f\"Le fichier '{filename}' est prÃªt.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
